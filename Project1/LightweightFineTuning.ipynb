{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "- PEFT technique: In this process, we use the LoRA (Low-Rank Adaptation) technique. This method allows us to fine-tune the model efficiently by making small adjustments to certain layers of the pre-trained model. Specifically, we will focus on the attention layers to enhance the model's performance.\n",
    "\n",
    "- Model: DistilBERT is a smaller, faster, cheaper, and lighter version of BERT. It retains 97% of BERT's language understanding capacity while being 60% faster and 40% smaller. It's well-suited for sequence classification tasks and is efficient for lightweight fine-tuning.\n",
    "\n",
    "- Evaluation approach: \n",
    "    - Accuracy: Measures the proportion of correct predictions.\n",
    "        \n",
    "    - Precision, Recall, and F1-Score: These metrics provide detailed insights into the model's performance for each class. Precision is the accuracy of positive predictions, recall is the ability to find all relevant cases, and F1-score balances both.\n",
    "        \n",
    "    - Confusion Matrix: Shows the distribution of correct and incorrect predictions across all classes.\n",
    "\n",
    "- Fine-tuning dataset: The AG News dataset is a popular text classification dataset that is used to categorize news articles into one of four classes: World, Sports, Business, and Sci/Tech. It's a balanced dataset with a manageable size for lightweight fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be9ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26fb44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "# Load the DistilBERT model and tokenizer\n",
    "model_name = 'distilbert-base-uncased'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,\n",
    "    id2label={0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"},\n",
    "    label2id={\"World\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3},\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4935cb4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a9d001d4024d26883ec3b06493f0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the AG News dataset\n",
    "dataset = load_dataset('ag_news')\n",
    "dataset['train'] = dataset['train'].shuffle(seed=23).select(range(5000))\n",
    "dataset['test'] = dataset['test'].shuffle(seed=23).select(range(1000))\n",
    "print(f\"dataset:\\n{dataset}\")\n",
    "# Preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "print(f\"encoded_dataset:\\n{encoded_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions\n",
    "\n",
    "small_test_dataset = dataset['test'].select(range(500))\n",
    "test_texts = small_test_dataset['text']\n",
    "true_labels = small_test_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b61cf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predict(test_texts).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "69aca781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.92      0.09      0.16       123\n",
      "      Sports       0.00      0.00      0.00       122\n",
      "    Business       0.21      0.26      0.23       136\n",
      "    Sci/Tech       0.31      0.82      0.45       119\n",
      "\n",
      "    accuracy                           0.29       500\n",
      "   macro avg       0.36      0.29      0.21       500\n",
      "weighted avg       0.36      0.29      0.21       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(true_labels, predicted_labels, target_names=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1fdf5",
   "metadata": {},
   "source": [
    "The model's accuracy is 29%, with poor performance overall. The World category has a high precision of 92% but very low recall, while the Sports category performed the worst with zero precision, recall, and f1-score. The Sci/Tech category did relatively better with a recall of 82%, but its precision is still low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5f5a7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[11  0 28 84]\n",
      " [ 0  0 87 35]\n",
      " [ 1  0 36 99]\n",
      " [ 0  0 22 97]]\n"
     ]
    }
   ],
   "source": [
    "confusion_mx = confusion_matrix(true_labels, predicted_labels)\n",
    "print(f\"Confusion Matrix:\\n{confusion_mx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1cb85",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the model struggled with accurate predictions. The model correctly identified 11 instances of the first class but misclassified many others, particularly confusing them with the fourth class. The second class had no correct predictions, with most being misclassified as the third or fourth class. The third and fourth classes had better performance but still faced significant misclassifications, mainly within each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87817cbc",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba7ffe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, AutoPeftModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c22295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,\n",
    "    id2label={0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"},\n",
    "    label2id={\"World\": 0, \"Sports\": 1, \"Business\": 2, \"Sci/Tech\": 3},\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91153cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules= [\"q_lin\", \"k_lin\", \"v_lin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "328f0e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, lora_config, \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03d41d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (v_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc5e2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ab8378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/categorize_news\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy='epoch',\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=4,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f58523b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [628/628 08:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.843264</td>\n",
       "      <td>0.845959</td>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.441993</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.869205</td>\n",
       "      <td>0.868875</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392974</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>0.870172</td>\n",
       "      <td>0.869868</td>\n",
       "      <td>0.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.701100</td>\n",
       "      <td>0.384063</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.875291</td>\n",
       "      <td>0.875095</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data/categorize_news/checkpoint-157 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/categorize_news/checkpoint-314 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=628, training_loss=0.6345494689455458, metrics={'train_runtime': 525.7429, 'train_samples_per_second': 38.041, 'train_steps_per_second': 1.195, 'total_flos': 1856498842560000.0, 'train_loss': 0.6345494689455458, 'epoch': 4.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab4d57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"model/lora-tuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d978b422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3840634822845459,\n",
       " 'eval_accuracy': 0.876,\n",
       " 'eval_f1': 0.8752911996601751,\n",
       " 'eval_precision': 0.8750954105500008,\n",
       " 'eval_recall': 0.876,\n",
       " 'eval_runtime': 6.2762,\n",
       " 'eval_samples_per_second': 159.332,\n",
       " 'eval_steps_per_second': 5.099,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce2e755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification, PeftModel\n",
    "fine_tuned_model = AutoPeftModelForSequenceClassification.from_pretrained('model/lora-tuned-model',num_labels = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35cd44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = dataset['test']['text']\n",
    "true_labels = dataset['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.88      0.85      0.86       241\n",
      "      Sports       0.94      0.98      0.96       253\n",
      "    Business       0.84      0.81      0.83       256\n",
      "    Sci/Tech       0.85      0.86      0.85       250\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = predict(test_texts).cpu().numpy()\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4dee6dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[205  12  18   6]\n",
      " [  3 248   1   1]\n",
      " [ 13   3 208  32]\n",
      " [ 13   2  20 215]]\n"
     ]
    }
   ],
   "source": [
    "confusion_mx = confusion_matrix(true_labels, predicted_labels)\n",
    "print(f\"Confusion Matrix:\\n{confusion_mx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78418559",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the model correctly predicted most instances for each class but had some misclassifications. Overall, it performed best on the second class with only one misclassification and worst on the fourth class with more errors across the other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b02b6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The initial model, without any fine-tuning, generated poor results. However, after fine-tuning the model, its performance significantly improved. The fine-tuned model achieved a much higher accuracy of 87%, with high precision and recall across all categories.\n",
    "\n",
    "This demonstrates the importance of fine-tuning in enhancing the model's reliability in classifying different categories, proving that fine-tuning can significantly elevate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9952778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
